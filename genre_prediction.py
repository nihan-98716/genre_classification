# -*- coding: utf-8 -*-
"""Genre Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v0I6cGui1A6ng5sBCz3YSg4meTe93ooG
"""

# Music Genre Classification using a Pre-Processed GTZAN CSV
# This script is lightweight, fully automated, and designed to prevent Colab crashes.

# --- 1. Setup and Dependencies ---#
# Install necessary libraries
!pip install matplotlib seaborn scikit-learn pandas kaggle tensorflow

import os
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
# Import layers for the 1D CNN, including BatchNormalization
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.decomposition import PCA

# --- 2. Data Acquisition (Lightweight CSV Method) ---
# Download the pre-processed features CSV file from a reliable source (Kaggle).
zip_file_name = "gtzan-dataset-music-genre-classification.zip"
extracted_csv_path = "Data/features_3_sec.csv"

# To download from Kaggle, you need to authenticate.
try:
    from google.colab import files
    if not os.path.exists('/root/.kaggle/kaggle.json'):
        print("Please upload your 'kaggle.json' API token.")
        files.upload()
        !mkdir -p ~/.kaggle
        !cp kaggle.json ~/.kaggle/
        !chmod 600 ~/.kaggle/kaggle.json
except ImportError:
    print("Not in a Colab environment. Assuming kaggle.json is already configured.")

# Download the entire dataset zip.
!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification

# Unzip the downloaded file
print(f"\nExtracting {zip_file_name}...")
with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:
    zip_ref.extractall()

# Check if the file was downloaded and extracted correctly
if not os.path.exists(extracted_csv_path):
    print(f"ERROR: Could not find '{extracted_csv_path}'. The extraction may have failed.")
    exit()

print(f"\nSuccessfully loaded '{extracted_csv_path}'")

# --- 3. Load and Prepare Data from CSV ---
# Load the data into a pandas DataFrame
df = pd.read_csv(extracted_csv_path)

# Drop unnecessary columns
df = df.drop(columns=['filename', 'length'])

# Separate features (X) and labels (y)
X = df.drop(columns=['label'])
y = df['label']

print(f"\nShape of features (X): {X.shape}")
print(f"Shape of labels (y): {y.shape}")
print(f"Available genres: {y.unique()}")

# --- 4. Data Preprocessing ---
# Encode the genre labels (strings) into integers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
num_classes = len(label_encoder.classes_)

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded
)

# Reshape data for the 1D CNN
# A CNN expects a 3D input: (samples, timesteps, features).
X_train = np.expand_dims(X_train, axis=2)
X_test = np.expand_dims(X_test, axis=2)

print("\nData preprocessing complete.")
print(f"Training set shape: {X_train.shape}")
print(f"Testing set shape: {X_test.shape}")

# --- 5. Model Training (Deeper 1D CNN for Highest Accuracy) ---
# This deeper architecture with Batch Normalization is designed for peak performance.
print("\nBuilding and Training the Deeper 1D CNN model...")
model = Sequential([
    # First Convolutional Block
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    Dropout(0.25),

    # Second Convolutional Block
    Conv1D(128, kernel_size=3, activation='relu'),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    Dropout(0.25),

    # Third Convolutional Block
    Conv1D(256, kernel_size=3, activation='relu'),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    Dropout(0.25),

    # Flatten the output to feed into the dense layers
    Flatten(),

    # Dense layer for classification
    Dense(128, activation='relu'),
    Dropout(0.5),

    # Output layer
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), # A slightly lower learning rate
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Define early stopping
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=30, # More patience for a deeper model
    restore_best_weights=True
)

# Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=300, # Increased epochs for the deeper model
    batch_size=32,
    callbacks=[early_stopping],
    verbose=0
)

print("Model training complete.")

# --- 6. Model Evaluation ---
# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"\nModel Accuracy: {accuracy * 100:.2f}%")

# Make predictions
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Generate a detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# --- 7. Data Visualization ---
# a) Confusion Matrix
print("\nVisualizing the Confusion Matrix...")
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.title('Confusion Matrix for Music Genre Classification')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# b) PCA Plot of Features
print("\nVisualizing features using PCA...")
pca = PCA(n_components=2)
# We need to reshape the scaled data back to 2D for PCA
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(14, 10))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='viridis', alpha=0.7)
plt.title('PCA of Music Genre MFCC Features')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
# Create a legend
legend1 = plt.legend(handles=scatter.legend_elements()[0],
                     labels=list(label_encoder.classes_),
                     title="Genres")
plt.gca().add_artist(legend1)
plt.grid(True)
plt.show()

print("\n--- Project Complete ---")
